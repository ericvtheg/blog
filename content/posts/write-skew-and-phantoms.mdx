---
title: Database Transaction are a Leaky Abstraction
description: Transactions are empowering for application developers, but the conversation doesn't stop there.
date: "2023-08-08"
---

As application developers, database transactions abstract us away from [concurrency control](https://www.geeksforgeeks.org/concurrency-control-in-dbms/#)
to let us design our systems as if just a single process is modifying state serially. [1] {/* 233 */}
Unfortunately it is not that simple.

Disclaimer: This article is influenced by Martin Kleppmann's book, _Designing Data-Intensive Applications_.

<p align="center">
  <a
    alt="Designing Data-Intensive Applications by Martin Kleppmann"
    target="_blank"
    href="https://www.amazon.com/Designing-Data-Intensive-Applications-Reliable-Maintainable/dp/1449373321/ref=sr_1_1?keywords=martin+kleppmann%2527s+designing+data-intensive+applications&amp;qid=1691551612&amp;sprefix=martin+klep%252Caps%252C192&amp;sr=8-1&_encoding=UTF8&tag=ericventor-20&linkCode=ur2&linkId=e1be69645fddf1c77e3edaeafb9d9c2a&camp=1789&creative=9325"
  >
    <img
      src="https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcSlR4hC5tiypE9ftFBwNG1qi90tsMqcjs3cZB1vZrk7qZ5YV3dt"
      alt="Book Cover"
    />
    Designing Data-Intensive Applications by Martin Kleppmann
  </a>
</p>

## Transactions & Concurrency Control

Database transactions give us the illusion that all operations are done serially.
If all our database operations were done serially we wouldn't need to worry about our
data being manipulated in ways we didn't anticipate.

This illusion is done through concurrency control via transaction isolation.
Transaction isolation can have detrimental _gotchas_ that we must be aware of.
In order to build robust systems we must thoroughly understand how transactions
work and what level of isolation our database provides.

## Transaction Isolation Levels

Transaction isolation refers to how the database itself handles data access.
Each isolation level has its own rules for when data can be read/written to.
Limiting access to other transactions is done through locking and serialization.
As data access becomes more and more strict there are trade-offs, we get stronger
data consistency, but weaker concurrency capacity.

Understanding how our databases writes and reads is crucial for mitigating the potential
of race conditions. To add onto the complexity there is no standard for isolation levels.
For example Snapshot isolation in PostgreSQL is called repetable read, while Oracle
calls it serializable. [pg 242]

Before diving into different transaction isolation levels, lets discuss
what we are trying to avoid.

## Race Conditions

Race conditions can occur when multiple processes attempt to modify data at the same time
leading to situations where unexpected outcomes occur.

An example of a race condition can be as benign as a user creating an account
but not seeing their profile when they refresh the page.
[A race condition can also be as sinister as bankrupting a CryptoConcurrency exchange](https://old.reddit.com/r/Bitcoin/comments/1wtbiu/how_i_stole_roughly_100_btc_from_an_exchange_and/).

Race conditions are tricky to test for because they only occur when we get unlucky with timing. [2] {/* 233 */}
To understand the depth of what in our software stack can be 'unlucky' we must recognize
that anomalies can occur anywhere from the top of the software stack all the way to the
hardware at the bottom. For the purpose of this article we will focus on the race conditions
that can occur in our database and how we can mitigate them using different transaction isolation levels.

### Mitigating Race Conditions

In this section we will go through race condition examples and discuss how they could be avoided
with different transation isolation levels.

### Read Committed

The most basic level of transaction isolation is read committed. It makes two guarantees:

> 1. When reading from the database, you will only see data that has been committed (no dirty reads).
> 2. When writing to the database, you will overwrite data that has been commited (no dirty writes).

<cite>&mdash; Martin Kleppmann</cite>

#### Race Condition Example

The race conditions prevented by read committed isolation level are fundamental to database integrity.
A fundamental example is maintaining state between multiple rows within a schema.

For this exmaple a user has bank accounts X and Y. They decide to transfer $10,000 from X and deposit into Y.
Since this entails two separate operations, this would require a database transaction
to ensure integrity in the operation. The result of the transaction should not be exposed
until it is fully completed. If this wasn't the case imagine that $10,000 was the total amount of money
the user had between bank accounts X and Y, in the middle of this operation executing the user refreshes the page.
Thus causing the user to see $0 between both bank accounts, a very uncomftorable situation for the user to be in.

Another case for this example could be the bank is determining how much to charge for the user's bank
accountfor the month. The bank has a policy where if the total dollars exceeds $5,000 then there is no
monthly bill. Unfortunately due to the lack of a transaction, the monthly billing service read $0 in
both accounts, causing a charge. A direct effect of the race condition with real world consequences.

### Snapshot Isolation and Repeatable Read

As the name implies, in the snapshot isolation transaction level, all transactions work on a snapshot
of the database from when the transaction began. Regardless if subsequent transactions commit, the
data that is being read/written will stay the same from the perspective of the transaction. [pg 232]

Snapshot isolation is used in PostgreSQL and MySQL and is referred to as repeatable read. [pg 242]

#### Race Condition Example

An excellent example of a race condition that is avoided through the use of snapshot isolation is
creating a database backup. Naturally when creating a backup of potentially several terabytes of data,
it will take a relatively long amount of time. Therefore exposing us to race conditions.

As the backup is created several unrelated transactions can complete, potentially exposing us to
inconsistencies in our data. If a user's bank account X was written to the backup with
$500, but later there was a transfer from bank account Y that sent $100 to bank account X.
Then shortly after bank account Y was written to the backup with $100 less than expected,
causing a user to mysteriously lose $100. With snapshot isolation for the entire length of
the backup creation process the database will remain consistent, allowing us to create a
reliable database backup.

### Serializable

#### Race Condition Example - Write Skew

Write skew is a more sly example of a race condition. This is due to it not being
able to be prevented using the listed transaction isolation levels.
Write skew is caused by phantoms, where we check for the abscence of data.

For example, I go to a fitness studio with live classes called Orange Theory
(not affiliated but I am a fan). I attend Orange Theory classes by going into the app
and booking a class. Naturally a class has a finite amount of capacity for people that
can not be exceeded, so the database operation probably looks something like:

```sql
INSERT Eric INTO SCHEDULED_ATTENDEES
WHERE SCHEDULED_ATTENDEES.class_id = X
AND 20 > (SELECT COUNT(*) FROM SCHEDULED_ATTENDEES WHERE class_id = X)
```

Excuse the crude example, but as you can see we're checking for the absence of rows in this query.
In this case we're checking that there is less than 20 people scheduled to attend class X.

What happens if we only have a single slot left for a class, and two users request to book at
the same time? For each request's database query there is less than 20 users at the
time, so the database does the insert and the request is successful. Now we have 21 users booked
for a class that only has capacity for 20 people. Even in a transaction there is no failure to
rollback in this case, the database schema itself has no constraint on the amount of scheduled
attendees for a class.

## Conclusion

this article doesn't even discuss replication which adds network, balancing, consensus, etc to the mix.

As much as we'd like to trust our abstractions and lean into them, we are forced to think about every layer's failure in our systems
and account for them.
