---
title: Database Transaction are a Leaky Abstraction
description: Transactions are empowering for application developers, but the conversation doesn't stop there.
date: "2023-08-08"
---

As application developers, database transactions abstract us away from [concurrency control](https://www.geeksforgeeks.org/concurrency-control-in-dbms/#)
to let us design our systems as if just a single process is modifying state serially. [1] {/* 233 */}
Unfortunately it is not that simple.

Disclaimer: This article is influenced by Martin Kleppmann's book, _Designing Data-Intensive Applications_.

<p align="center">
  <a
    alt="Designing Data-Intensive Applications by Martin Kleppmann"
    target="_blank"
    href="https://www.amazon.com/Designing-Data-Intensive-Applications-Reliable-Maintainable/dp/1449373321/ref=sr_1_1?keywords=martin+kleppmann%2527s+designing+data-intensive+applications&amp;qid=1691551612&amp;sprefix=martin+klep%252Caps%252C192&amp;sr=8-1&_encoding=UTF8&tag=ericventor-20&linkCode=ur2&linkId=e1be69645fddf1c77e3edaeafb9d9c2a&camp=1789&creative=9325"
  >
    <img
      src="https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcSlR4hC5tiypE9ftFBwNG1qi90tsMqcjs3cZB1vZrk7qZ5YV3dt"
      alt="Book Cover"
    />
    Designing Data-Intensive Applications by Martin Kleppmann
  </a>
</p>

## Transactions & Concurrency Control

Database transactions give us the illusion that all operations are done serially.
If all our database operations were done serially we wouldn't need to worry about our
data being manipulated in ways we didn't anticipate.

This illusion is done through concurrency control via transaction isolation.
Transaction isolation can have detrimental _gotchas_ that we must be aware of.
In order to build robust systems we must thoroughly understand how transactions
work and what level of isolation our database provides.

## Transaction Isolation Levels

Transaction isolation refers to how the database itself handles data access.
Each isolation level has its own rules for when data can be read/written to.
Limiting access to other transactions is done through locking and serialization.
As data access becomes more and more strict there are trade-offs, we get stronger
data consistency, but weaker concurrency capacity.

Understanding how our databases writes and reads is crucial for mitigating the potential
of race conditions. To add onto the complexity there is no standard for isolation levels.
For example Snapshot isolation in PostgreSQL is called repetable read, while Oracle
calls it serializable. [pg 242]

Before diving into different transaction isolation levels, lets discuss
what we are trying to avoid.

## Race Conditions

Race conditions can occur when multiple processes attempt to modify data at the same time
leading to situations where unexpected outcomes occur.

An example of a race condition can be as benign as a user creating an account
but not seeing their profile when they refresh the page.
[A race condition can also be as sinister as bankrupting a CryptoConcurrency exchange](https://old.reddit.com/r/Bitcoin/comments/1wtbiu/how_i_stole_roughly_100_btc_from_an_exchange_and/).

Race conditions are tricky to test for because they only occur when we get unlucky with timing. [2] {/* 233 */}
To understand the depth of what in our software stack can be 'unlucky' we must recognize
that anomalies can occur anywhere from the top of the software stack all the way to the
hardware at the bottom. For the purpose of this article we will focus on the race conditions
that can occur in our database and how we can mitigate them using different transaction isolation levels.

### Mitigating Race Conditions

In this section we will go through race condition examples and discuss how they could be avoided
with a specific transation isolation level.

### Read Committed

Does x and solves y race condition

### Snapshot Isolation and Repeatable Read

Does x and solves y race condition.

### Serializable

Does x and solves write skew race condition.

### Write Skew

Write skew is a more sly example of a race condition. This is due to it not being able to be prevented
using the most transaction isolation levels as we'd traditionally expect. Write skew is caused by phantoms, where
we check for the abscence of data.

For example, I go to a fitness studio with live classes called Orange Theory
(not affiliated but I am a fan). I attend Orange Theory classes by going into the app
and booking a class. Naturally a class has a finite amount of capacity for people that
can not be exceeded, so the database operation probably looks something like:

```sql
INSERT Eric INTO SCHEDULED_ATTENDEES
WHERE SCHEDULED_ATTENDEES.class_id = X
AND 20 > (SELECT COUNT(*) FROM SCHEDULED_ATTENDEES WHERE class_id = X)
```

Excuse the crude example, but as you can see we're checking for the absence of rows in this query.
In this case we're checking that there is less than 20 people scheduled to attend class X.

What happens if we only have a single slot left for a class, and two users request to book at
the same time? For each request's database query there is less than 20 users at the
time, so the database does the insert and the request is successful. Now we have 21 users booked
for a class that only has capacity for 20 people. Even in a transaction there is no failure to
rollback in this case, the database schema itself has no constraint on the amount of scheduled
attendees for a class.

Write skews are devious.

(example)

## Conclusion

this article doesn't even discuss replication which adds network, balancing, consensus, etc to the mix.

As much as we'd like to trust our abstractions and lean into them, we are forced to think about every layer's failure in our systems
and account for them.
